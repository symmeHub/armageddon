{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orientation an aspect ratio\n",
    "\n",
    "In this example, we show how to use inertia matrix of a given labeled object to find its orientation. \n",
    "\n",
    "![](./blobs.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Required files\n",
    ":class: important\n",
    "Before using this notebook, download the image {download}`blobs.jpg <blobs.jpg>`\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"blobs.jpg\"\n",
    "files = os.listdir(\"./\")\n",
    "if path in files:\n",
    "    print(\"Ok, the file is in {0}\".format(files))\n",
    "else:\n",
    "    print(\"The file is not in {0} , retry !\".format(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to explain the concepts of inertia and aspect ratio, we use this magnificient hand drawing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(path)\n",
    "# Resizing image\n",
    "Nr, Nc = im.size\n",
    "im = im.resize((Nr // 4, Nc // 4))\n",
    "# Plot image\n",
    "plt.figure()\n",
    "plt.title(\"Blobs\")\n",
    "plt.ylabel(\"rows\")\n",
    "plt.xlabel(\"columns\")\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `PIL.Image.split()` class method to extract the color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R, G, B = im.split()\n",
    "R = np.array(R)\n",
    "G = np.array(G)\n",
    "B = np.array(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{seealso}\n",
    "The same can be achieved by using `numpy` slicing, as the image is represented as a 3D array of shape (height, width, channels).\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "# Converting the image to a numpy array\n",
    "image_array = np.array(image)\n",
    "# Extracting the color channels\n",
    "R = image_array[:, :, 0]  # Red channel\n",
    "G = image_array[:, :, 1]  # Green channel\n",
    "B = image_array[:, :, 2]  # Blue channel\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel extraction and histogram\n",
    "We can display every channel separately to see the differences and plot the histogram of pixel values for each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = GridSpec(2, 3, width_ratios=[1, 1, 1], height_ratios=[1, 1])\n",
    "ax0 = fig.add_subplot(gs[0, 0])\n",
    "ax1 = fig.add_subplot(gs[0, 1])\n",
    "ax2 = fig.add_subplot(gs[0, 2])\n",
    "img_axs = [ax0, ax1, ax2]\n",
    "\n",
    "ax0.imshow(R, cmap=\"gray\")\n",
    "ax1.imshow(G, cmap=\"gray\")\n",
    "ax2.imshow(B, cmap=\"gray\")\n",
    "ax0.set_title(\"red channel\")\n",
    "ax1.set_title(\"green channel\")\n",
    "ax2.set_title(\"blue channel\")\n",
    "[ax.axis(\"off\") for ax in img_axs]\n",
    "\n",
    "ax4 = fig.add_subplot(gs[1, :])\n",
    "ax4.hist(R.flatten(), bins=np.arange(256), histtype=\"step\", color=\"red\", label=\"red\")\n",
    "ax4.hist(\n",
    "    G.flatten(), bins=np.arange(256), histtype=\"step\", color=\"green\", label=\"green\"\n",
    ")\n",
    "ax4.hist(B.flatten(), bins=np.arange(256), histtype=\"step\", color=\"blue\", label=\"blue\")\n",
    "ax4.set_title(\"Histogramms\")\n",
    "ax4.set_xlabel(\"pixel value\")\n",
    "ax4.set_ylabel(\"count\")\n",
    "ax4.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding and binary image\n",
    "As we can deduce from the histograms, the thresholding level is obvious and can be set to 50 for all channels. For the sake of simplicity, we will use the blue channel to find the orientation and aspect ratio of the blobs. Here we use [`where()`](https://numpy.org/devdocs/reference/generated/numpy.where.html) from numpy module to create a binary image based on the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bt = np.where(B < 50, 1, 0)\n",
    "plt.figure()\n",
    "plt.imshow(Bt, cmap=cm.gray)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling from binary image\n",
    "After thresholding, we can use [`scipy.ndimage.label`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.label.html) to label the connected components in the binary image. This will give us a labeled image where each blob has a unique label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Btc = ndimage.binary_closing(Bt, structure=np.ones((5, 5)))\n",
    "\n",
    "Bl, number = ndimage.label(Btc)\n",
    "plt.figure()\n",
    "plt.imshow(np.where(Bl != 0, Bl, np.nan), cmap=cm.jet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = ndimage.find_objects(Bl)\n",
    "len(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inertia matrix of an object\n",
    "\n",
    "The object represented bellow is stretched in a direction. Let's see how we can use its inertia matrix to determine in which direction and how much it is stretched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.array(im)[obj[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inertia matrix of a 2D object can be defined as follows:\n",
    "\n",
    "$$\n",
    "I = \n",
    "\\begin{bmatrix} \n",
    "I_{xx} & -I_{xy} \\\\\n",
    "-I_{xy} & I_{yy} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This matrix is symmetric and, as a consequence, it can be diagonalized in a new frame rotated by an angle $\\theta$ in the plane. This frame is composed of the two normalized eigenvectors $(\\vec e_1, \\vec e_2)$ of the matrix. In this frame, the matrix has two eigenvalues $(I_1, I_2)$ ordered so that $I_1 \\geq I_2$. Then: \n",
    "* $\\theta = (\\vec x, \\vec e_1)$ and,\n",
    "* The aspect ratio $a = \\sqrt{I_1 / I_2}$.\n",
    "\n",
    "The angle $\\theta$ gives the direction of the elongation of the object and $a$ shows how much it is elongated. For example,  if $a == 1$, the object is not elongated whereas if $a=10$ it is 10 times longer in direction 1 than in direction 2 in an inertial point of view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(\n",
    "    columns=[\"area\", \"xg\", \"yg\", \"Ixx\", \"Iyy\", \"Ixy\", \"I1\", \"I2\", \"theta\"]\n",
    ")\n",
    "for i in range(len(obj)):\n",
    "    x, y = np.where(Bl == i + 1)\n",
    "    xg, yg = x.mean(), y.mean()\n",
    "    x = x - xg\n",
    "    y = y - yg\n",
    "    A = len(x)\n",
    "    Ixx = (y**2).sum()\n",
    "    Iyy = (x**2).sum()\n",
    "    Ixy = (x * y).sum()\n",
    "    I = np.array([[Ixx, -Ixy], [-Ixy, Iyy]])\n",
    "    eigvals, eigvecs = np.linalg.eig(I)\n",
    "    eigvals = abs(eigvals)\n",
    "    loc = np.argsort(eigvals)[::-1]\n",
    "    d = eigvecs[loc[0]]\n",
    "    d *= np.sign(d[0])\n",
    "    theta = np.degrees(np.arccos(d[1]))\n",
    "    eigvals = eigvals[loc]\n",
    "    data.loc[i] = [A, xg, yg, Ixx, Iyy, Ixy, eigvals[0], eigvals[1], theta]\n",
    "data.sort_values(\"area\", inplace=True, ascending=False)\n",
    "data[\"aspect_ratio\"] = (data.I1 / data.I2) ** 0.5\n",
    "\n",
    "data[[\"area\", \"theta\", \"aspect_ratio\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "counter = 1\n",
    "for i in data.index.values:\n",
    "    ax = fig.add_subplot(3, 4, counter)\n",
    "    z = Image.fromarray(np.array(im)[obj[i]])\n",
    "    z = z.rotate(-data.loc[i, \"theta\"] + 90, expand=True)\n",
    "    z = np.array(z)\n",
    "    plt.imshow(z)\n",
    "    plt.title(str(i))\n",
    "    ax.axis(\"off\")\n",
    "    counter += 1\n",
    "    # plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
