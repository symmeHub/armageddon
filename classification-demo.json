{"version":3,"kind":"Notebook","sha256":"98312e54a71ab2828256357c3ef4ac5204688d32f961154c9340b3087af7c225","slug":"classification-demo","location":"/machine_learning/exercises/tutorials/classification_demo.ipynb","dependencies":[],"frontmatter":{"title":"Supervised learning using PyTorch: a toy example","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"science","language":"python"},"github":"https://github.com/symmeHub/positron","numbering":{"title":{"offset":2}},"source_url":"https://github.com/symmeHub/positron/blob/main/book/machine_learning/exercises/tutorials/classification_demo.ipynb","edit_url":"https://github.com/symmeHub/positron/edit/main/book/machine_learning/exercises/tutorials/classification_demo.ipynb","thumbnail":"/armageddon/build/c527b5d0c9d330c6d219c4ff7ef023c9.svg","exports":[{"format":"ipynb","filename":"classification_demo.ipynb","url":"/armageddon/build/classification_demo-13507c738db741c3fcf115c4d1cc0aff.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Introduction","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"TspJaTo6Yf"}],"identifier":"introduction","label":"Introduction","html_id":"introduction","implicit":true,"key":"WrIHg1fgaD"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"In this example, you will use a supervised learning strategy to train a neural network.\nThe example is deliberately very simple to allow for great scalability and fast CPU learning.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"bN1jKaink1"}],"key":"iFKMjexGpU"}],"key":"WygnzzZD2n"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"%matplotlib widget\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport pandas as pd\nfrom scipy import optimize\nimport numba\nimport torch\nfrom IPython.display import YouTubeVideo","key":"WNyMvHRAiP"},{"type":"outputs","id":"Tdikoa0Vy5fmtXM7OPnP2","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"error","traceback":"\u001b[31m---------------------------------------------------------------------------\u001b[39m\n\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)\n\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m optimize\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumba\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YouTubeVideo\n\n\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'","ename":"ModuleNotFoundError","evalue":"No module named 'torch'"},"key":"RMKHYvcpAk"}],"key":"EahPkriWUi"}],"key":"nb5sjag7x0"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"YouTubeVideo(\"aircAruvnKk\")","key":"wRQJuyoM2x"},{"type":"outputs","id":"yfCCEgBLfw8ekRQnZfqqY","children":[],"key":"jCOiFOEgp3"}],"key":"ZVLNofaX9C"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Exact model","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"r3Jk1Vi7ho"}],"identifier":"exact-model","label":"Exact model","html_id":"exact-model","implicit":true,"key":"ETeTO50qPd"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"In this first part, we propose to define an ideal classification model. It is a function which associates a value ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"s8OqBL8O2K"},{"type":"inlineMath","value":"z \\in \\left\\lbrace 0, 1 \\right \\rbrace","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>z</mi><mo>∈</mo><mrow><mo fence=\"true\">{</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo fence=\"true\">}</mo></mrow></mrow><annotation encoding=\"application/x-tex\">z \\in \\left\\lbrace 0, 1 \\right \\rbrace</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">{</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\">1</span><span class=\"mclose delimcenter\" style=\"top:0em;\">}</span></span></span></span></span>","key":"UvKpyy1wsT"},{"type":"text","value":" to a tuple of values ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"UELjFmJvbX"},{"type":"inlineMath","value":"(x, y)","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(x, y)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span>","key":"h5YJFQsIrt"},{"type":"text","value":". This function represents categories or classes that we would like to model the distribution in space. In a real case, this function would be inaccessible to us and we would try to find it through deep learning.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"UrQjBSa2IS"}],"key":"ms8zITcZt3"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"We propose two examples of functions but you are encouraged to develop your own and to test them.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"EaM2crSnNe"}],"key":"dwFRGfPlNa"}],"key":"OwjNwnyozf"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def func_easy(inp):\n    \"\"\"\n    A ideal model.\n    \"\"\"\n    xc1, yc1 = 0.3, 0.6\n    xc2, yc2 = 0.55, 0.15\n    r1, r2 = 0.25, 0.15\n    X, Y = np.array(inp).T\n    R12 = (X - xc1) ** 2 + (Y - yc1) ** 2\n    R22 = (X - xc2) ** 2 + (Y - yc2) ** 2\n    return ((R22 <= r2**2) | (R12 <= r1**2)) * 1\n\n\ndef func_hard(inp):\n    \"\"\"\n    Another ideal model, just a bit more complex.\n    \"\"\"\n    x, y = np.array(inp).T - 0.5\n    r = np.sqrt(x**2 + y**2)\n    theta = np.arccos(x / r) * np.sign(y)\n    out = (np.cos(3 * theta + 10 * r) >= 0.0) * 1\n    out[r <= 0.1] = 1\n    return out\n\n\nexact_model = func_easy","key":"GXCF5LRnSS"},{"type":"outputs","id":"1KhBb8Vi9ztjVF78gOP7I","children":[],"key":"lxujvVvtiY"}],"key":"VyOccOBFUj"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"In what follows, we draw the model to see what it looks like.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GdcUWNC4j8"}],"key":"Zxl7vCqJ8f"}],"key":"GWTHUhJCNG"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"nxm, nym = 200, 200\nxm = np.linspace(0, 1.0, nxm)\nym = np.linspace(0, 1.0, nym)\nXm, Ym = np.meshgrid(xm, ym)\npointsm = np.array([Xm.flatten(), Ym.flatten()]).T\nsolm = exact_model(pointsm)\nsolm","key":"vzW8yYwLyp"},{"type":"outputs","id":"iMZd9o39kng7AzZ1uvki1","children":[],"key":"VUx6adNdnT"}],"key":"XH72RaXWRM"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots(1, 1)\nax.set_aspect(\"equal\")\nplt.scatter(\n    pointsm[solm == 1].T[0], pointsm[solm == 1].T[1], s=1, color=\"white\", label=\"Ones\"\n)\nplt.scatter(\n    pointsm[solm == 0].T[0], pointsm[solm == 0].T[1], s=1, color=\"black\", label=\"Zeros\"\n)\nplt.legend()\nplt.show()","key":"nqD5uwVTDt"},{"type":"outputs","id":"L1cRz2pKjTbjnxnGAo8NZ","children":[],"key":"tikXYn63Wc"}],"key":"BqEFFvUfCa"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Learning DB","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"I2NV4SY2UF"}],"identifier":"learning-db","label":"Learning DB","html_id":"learning-db","implicit":true,"key":"MsGuW7aKfF"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"First, we will create a learning database. This one contains a certain number of points for which we know the class. The goal is to present them to our neural network so that it can learn to recognize the different classes. These points are randomly arranged in the space where the function is defined. We can vary the number of points and see how this affects the learning capacity of the network.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"HIul23Od9H"}],"key":"Z30IaLu9lD"}],"key":"lygUymuGef"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"npl = 2000  # NUMBER OF SAMPLES\npointsl = np.random.rand(npl * 2).reshape(npl, 2)\nsoll = exact_model(pointsl)","key":"UMFrdhsUG4"},{"type":"outputs","id":"MdurYykxfrboJJC3s0hFo","children":[],"key":"aUPlQ1Mkfc"}],"key":"VqnpIOURdM"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots(1, 1)\nax.set_aspect(\"equal\")\nplt.scatter(\n    pointsl[soll == 1].T[0], pointsl[soll == 1].T[1], s=2, color=\"red\", label=\"Ones\"\n)\nplt.scatter(\n    pointsl[soll == 0].T[0], pointsl[soll == 0].T[1], s=2, color=\"blue\", label=\"Zeros\"\n)\nplt.legend()\nplt.show()","key":"Riiykg6Fkp"},{"type":"outputs","id":"BDOwn1TP8IfgBs3Zw3fnM","children":[],"key":"ROzOOcFtxR"}],"key":"lD8n01mWoE"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Neural Network class","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PsLYV8fGEE"}],"identifier":"neural-network-class","label":"Neural Network class","html_id":"neural-network-class","implicit":true,"key":"yq2NvAZteS"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"A neural network is a stack of alternating layers. Linear layers where a linear (or affine) function is applied to the data and non-linear layers where a non-linear function or activation function (or neural function) is applied to the data. Building a network is therefore a matter of choosing the number of layers and the type of neural functions. The learning process only consists in optimizing the weights present in the linear layers. Neural functions do not usually have adjustable parameters.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"DyAnvG9G2S"}],"key":"CB9FF0uByL"},{"type":"image","url":"/armageddon/build/c527b5d0c9d330c6d219c4ff7ef023c9.svg","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"Er4exPrt5n","urlSource":"https://upload.wikimedia.org/wikipedia/commons/4/46/Colored_neural_network.svg"},{"type":"paragraph","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Evaluating the result of the network (inference) is the same as going from left to right, we speak of a forward path. On the contrary, to make it learn in a supervised approach, we have to analyze the effect of the different weights on the result and on the error it generates. This is called a backward path.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"idEiWsku4X"}],"key":"wI8OwyjKAq"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"You are asked to create your network and to test it.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"cSEj6YU6Vh"}],"key":"cbIsHNSCLL"},{"type":"heading","depth":2,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Required work","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"z5gbKkDfr8"}],"identifier":"required-work","label":"Required work","html_id":"required-work","implicit":true,"key":"kmB2eUfVpt"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":14,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Try the code in the state it is in. Do you think it is effective?","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"Y3OVDb19cI"}],"key":"FOO8kQTI5j"}],"key":"wZoAOgamtN"}],"key":"qYp5DKBTWK"},{"type":"paragraph","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"In particular, compare the level of error displayed during learning with the quality of the figure obtained at the end of the notebook.","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"maPq2FLUyD"}],"key":"IRytbJpHt1"},{"type":"list","ordered":true,"start":2,"spread":false,"position":{"start":{"line":18,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":18,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"Try to improve it by playing on: the training dataset, the network structure. Draw conclusions.","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"KEL0Mb9YFr"}],"key":"JGffOR3jf4"}],"key":"QzUIWUjA5m"},{"type":"listItem","spread":true,"position":{"start":{"line":20,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"Try the different neural functions and see how they affect the behavior of the network.","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"fYJ38CkFyk"}],"key":"Xsg0Mxhg1P"}],"key":"VN6GhAtciT"},{"type":"listItem","spread":true,"position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"text","value":"Try the ","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"FH8GF6fL0O"},{"type":"inlineCode","value":"func_hard","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"ZUQ1Z0m5M6"},{"type":"text","value":" function (see above), which has a more difficult structure to reproduce than the default.","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"vAst4h4ATd"}],"key":"duk2V1ekJT"}],"key":"Wlalrb90ND"}],"key":"RVuN5msmU8"}],"key":"FLvjQABqub"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"device = \"cpu\"\nerrors = []\nsteps = []\n# BUILD LAYERS WITH:\n# LINEAR LAYERS:\ntorch.nn.Linear(2, 4, bias=True)  # LINEAR LAYERS\n# NEURAL FUNCTIONS:\ntorch.nn.ELU, torch.nn.ReLU, torch.nn.Hardtanh  # POSSIBLE ACTIVATION FUNCTIONS\nactivation_func = torch.nn.ReLU\n\n# LAYERS INITIALIZATION\nlayers = [\n    torch.nn.Linear(2, 4, bias=True),\n    activation_func(),\n    torch.nn.Linear(4, 1, bias=True),\n    torch.nn.Hardtanh(min_val=0.0, max_val=1.0),\n]\nmodel = torch.nn.Sequential(*layers).to(device)\nlayers","key":"sfmGJKzWlU"},{"type":"outputs","id":"V3QKin0Mj8hpUr26On45p","children":[],"key":"lYaeptKnGl"}],"key":"MrPLBc5E5n"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# TRAINING INPUTS / OUTPUTS\n# NOTE: YOU CAN RERUN THIS CELL TO CONTINUE TRAINING PROCESS\nrun_training = True  # SET TO True TO ACTUALLY RUN TRAINING\nif run_training:\n    x = torch.Tensor(pointsl).to(device)\n    t = torch.Tensor(soll[:, None]).to(device)\n    ns = x.shape[0]\n    learning_rate = 1e-3\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    loss_fn = torch.nn.MSELoss(reduction=\"sum\").to(device)\n    Ne = 10  # Number of training epoch\n    Nes = 100  # Number of training steps per epoch\n    error = np.zeros(Ne)\n    step = np.arange(Ne) * Nes\n    if len(steps) != 0:\n        step += steps[-1].max() + Nes\n    # TRAINING\n    for e in range(Ne):\n        for s in range(Nes):\n            y = model(x)\n            loss = loss_fn(y, t)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        error[e] = loss.item() / ns\n        err_str = \"{0:.3f}\".format(error[e] * 100).zfill(6)\n        print(f\"Loss = {err_str}\")\n    errors.append(error)\n    steps.append(step)\n\n# POST-PROCESSING\nif run_training:\n    errors2 = np.array(errors)\n    fig = plt.figure()\n    plt.title(\"Training process\")\n    # plt.yscale(\"log\")\n    for ep, err in enumerate(errors2):\n        plt.plot(steps[ep], err * 100, \"x-\", label=f\"Epoch {ep}\")\n    plt.xlabel(\"Steps\")\n    plt.ylabel(\"Loss [%]\")\n    # plt.yscale(\"log\")\n    plt.legend()\n    plt.grid()","key":"fh1BIzLzNt"},{"type":"outputs","id":"omhwGvxdROuFPzzQTDBD6","children":[],"key":"jXVWHEzKaG"}],"key":"PsQo2D8Gi9"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"if run_training:\n    yt = model(torch.Tensor(pointsm).to(device)).cpu().data.numpy().ravel()\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 3, 1)\n    ax.set_aspect(\"equal\")\n    plt.title(\"Model\")\n    plt.tricontourf(pointsm.T[0], pointsm.T[1], solm, 2, cmap=mpl.cm.gray)\n    ax.axis(\"off\")\n    ax = fig.add_subplot(1, 3, 2)\n    ax.set_aspect(\"equal\")\n    plt.title(\"Learned\")\n    plt.tricontourf(pointsm.T[0], pointsm.T[1], yt, cmap=mpl.cm.gray)\n    ax.axis(\"off\")\n    ax = fig.add_subplot(1, 3, 3)\n    ax.set_aspect(\"equal\")\n    plt.title(\"Error\")\n    plt.tricontourf(pointsm.T[0], pointsm.T[1], yt - solm, cmap=mpl.cm.gray)\n    ax.axis(\"off\")\n    plt.show()","visibility":"show","key":"kcNK1ZPC7t"},{"type":"outputs","id":"bwU56zUte8pmfbTcrqXFn","children":[],"visibility":"show","key":"mXn0OaTxLV"}],"visibility":"show","key":"SKIEcFsyWi"}],"key":"OGeduRFv4q"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Exercices","url":"/exercises-5","group":"Machine Learning"},"next":{"title":"Reinforcement learning on snake with a genetic neural network","url":"/genetic-snake-practical-work","group":"Machine Learning"}}},"domain":"http://localhost:3002"}